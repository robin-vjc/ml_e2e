services:
  test:
    # command: tail -F keep_alive
    build:
      context: "."
      target: "test"
    volumes:
      - ".:/app/"

  train:
    # command: tail -F keep_alive
    build:
      context: "."
      target: "web"
    command: python ml_e2e/train.py
    environment:
      MLFLOW_SERVER_HOST: "http://mlflow:5000"
    volumes:
      - ".:/app/"
    networks:
      - ml_e2e

  web:
    build:
      context: "."
      target: "web"
    image: ghcr.io/robin-vjc/endeavour_e2e_ml
    depends_on:
      - mlflow
    healthcheck:
      test: "curl localhost:8000/health"
      interval: "60s"
      timeout: "3s"
      start_period: "5s"
      retries: 3
    ports:
      - "8000:8000"
    tty: true
    # command: tail -F keep_alive
    volumes:
      - ".:/app/"
    networks:
      - ml_e2e

  mlflow:
    build:
      context: "."
      target: "mlflow"
    ports:
      - "5000:5000"
    volumes:
      - ".:/app/"
    networks:
      - ml_e2e

networks:
  ml_e2e:
    driver: bridge